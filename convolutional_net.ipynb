{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network**:\n",
    "We will now replace the hidden layer from our simple neural network model with a `convolutional layer`. In the usual hidden layer, we multiply the input vector `L0` with a weights matrix `W0`. When the input size is large, i.e. each instance has a large number of feature attributes (e.g. in the case of image data with lots of pixels), we end up with a large number of weights in `W0`. This can lead to the model overfitting the training data and lower the accuracy of the predictions. This problem can be mitigated by introducing a smaller weights matrix, also called a `kernel`, and applying this `kernel` repeatedly over different subsections of the data. So for example, if we have a 28x28 (=784) pixel image input, then instead of multiplying with a weight matrix with 28x28 columns, we can use a 6x6 kernel and multiply it with every 6x6 subsection of the image. We can also use multiple different kernels to process the inputs and pass on a combination of the different kernel outputs onto the next layer.         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Relu function\n",
    "def Relu(x):\n",
    "    return x*(x > 0)\n",
    "\n",
    "# Relu derivative function\n",
    "def Relu_deriv(x):\n",
    "    return (x > 0)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(x):\n",
    "    return (1.0 - np.tanh(x)**2)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-1.0 * x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x)) \n",
    "\n",
    "def softmax(x): \n",
    "    ex = np.exp(x)\n",
    "    return ex/np.sum(ex, axis = 1, keepdims = True)  \n",
    "\n",
    "\n",
    "class convolutional_layer(object):\n",
    "\n",
    "    '''\n",
    "        class constructor\n",
    "    '''\n",
    "    def __init__(self, K, image_rows, image_cols, kernel_rows, kernel_cols, activation) -> None:\n",
    "        self.K = K\n",
    "        self.image_cols = image_cols\n",
    "        self.image_rows = image_rows\n",
    "        self.kernel_cols = kernel_cols\n",
    "        self.kernel_rows = kernel_rows\n",
    "        self.activation = activation\n",
    "    \n",
    "    ''' \n",
    "        convolutional layer forward propagation\n",
    "    '''\n",
    "    def forward(self, L, dropout):\n",
    "       \n",
    "        # reshape the input image array\n",
    "        L = L.reshape(L.shape[0], self.image_rows, self.image_cols)\n",
    "\n",
    "        # get all sub-sections from the image\n",
    "        sections = []\n",
    "        for i in range(self.image_rows-self.kernel_rows+1):\n",
    "            for j in range(self.image_cols-self.kernel_cols+1):\n",
    "                section = L[:,i:i+self.kernel_rows, j:j+self.kernel_cols]   \n",
    "                section = section.reshape(-1,1,self.kernel_rows,self.kernel_cols)\n",
    "                sections.append(section)\n",
    "     \n",
    "        # concatenate all sections into a single array\n",
    "        expanded_input = np.concatenate(sections, axis=1)    \n",
    "        input_shape = expanded_input.shape \n",
    "        print(f\"expanded input shape: {input_shape} \")\n",
    "        \n",
    "        # flatten the sections\n",
    "        self.flattened_input = expanded_input.reshape(expanded_input.shape[0]*expanded_input.shape[1], -1) \n",
    "        print(f\"flattened input shape: {self.flattened_input.shape}\")\n",
    "        #print(expanded_input)\n",
    "\n",
    "        return self.kernel_mult(input_shape, dropout)\n",
    "    \n",
    "    def kernel_mult(self, input_shape, dropout):\n",
    "\n",
    "        # matrix multiplication of flattened image sections with kernels\n",
    "        self.Z = np.dot(self.flattened_input, self.K) \n",
    "        print(f\"kernel output shape: {self.Z.shape}\")\n",
    "        print(self.Z)\n",
    "        \n",
    "        # flatten the kernel output for each image\n",
    "        self.Zflat = self.Z.copy()        \n",
    "        self.Zflat = self.Zflat.reshape(input_shape[0], -1)        \n",
    "        print(f\"kernel output flattened shape: {self.Zflat.shape}\")\n",
    "        print(self.Zflat)\n",
    "\n",
    "        self.dropout = dropout \n",
    "        if(self.dropout):\n",
    "            # generate a random dropout mask with rougly equal numbers of 0s and 1s\n",
    "            self.dropout_mask = np.random.randint(0,2,size=(self.Zflat.shape))\n",
    "    \n",
    "        if(self.activation == \"relu\"):\n",
    "            if(self.dropout):\n",
    "              # multiply by a factor of 2 to compensate for rougly 1/2 the neurons being turned off by the masking\n",
    "              return 2 * self.dropout_mask * self.forward_relu()\n",
    "            else:\n",
    "                return self.forward_relu()\n",
    "    \n",
    "        elif(self.activation == \"sigmoid\"):\n",
    "            if(self.dropout):\n",
    "              return 2 * self.dropout_mask * self.forward_sigmoid()\n",
    "            else:\n",
    "                return self.forward_sigmoid()\n",
    "    \n",
    "        elif(self.activation == \"tanh\"):\n",
    "            if(self.dropout):\n",
    "              return 2 * self.dropout_mask * self.forward_tanh()\n",
    "            else:\n",
    "                return self.forward_tanh()\n",
    "    \n",
    "    def forward_relu(self):\n",
    "        return Relu(self.Zflat)\n",
    "    \n",
    "    def forward_sigmoid(self):\n",
    "        return sigmoid(self.Zflat)\n",
    "   \n",
    "    def forward_tanh(self):\n",
    "        return tanh(self.Zflat)\n",
    "    \n",
    "    ''' \n",
    "        convolutional layer backpropagation\n",
    "    '''\n",
    "    def backward(self, D):\n",
    "        if(self.activation == \"relu\"):\n",
    "           self.backward_relu(D)\n",
    "        elif(self.activation == \"sigmoid\"):\n",
    "           self.backward_sigmoid(D)\n",
    "        elif(self.activation == \"tanh\"):\n",
    "           self.backward_tanh(D)\n",
    "\n",
    "    def backward_relu(self, D):\n",
    "        # dE/dZ\n",
    "        dE_dZ = D * Relu_deriv(self.Zflat) \n",
    "        self.backward_kernel_mult(dE_dZ)\n",
    "    \n",
    "    def backward_sigmoid(self, D):\n",
    "        # dE/dZ\n",
    "        dE_dZ = D * sigmoid_deriv(self.Zflat) \n",
    "        self.backward_kernel_mult(dE_dZ)\n",
    "    \n",
    "    def backward_tanh(self, D):\n",
    "        # dE/dZ\n",
    "        dE_dZ = D * tanh_deriv(self.Zflat) \n",
    "        self.backward_kernel_mult(dE_dZ)\n",
    "    \n",
    "    def backward_kernel_mult(self, D):\n",
    "        # dE/dW0\n",
    "        if(self.dropout):\n",
    "            self.W_grad = np.dot((self.flattened_input).T, self.dropout_mask * D.reshape(self.Z))\n",
    "        else:\n",
    "            self.W_grad = np.dot((self.flattened_input).T, D.reshape(self.Z))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden neurons: 32, Output neurons: 10\n",
      "expanded input shape: (2, 16, 3, 3) \n",
      "flattened input shape: (32, 9)\n",
      "kernel output shape: (32, 2)\n",
      "[[ 12.97390274  16.5086609 ]\n",
      " [ 17.4617429   22.51895906]\n",
      " [ 21.94958306  28.52925723]\n",
      " [ 26.43742322  34.53955539]\n",
      " [ 17.4617429   22.51895906]\n",
      " [ 21.94958306  28.52925723]\n",
      " [ 26.43742322  34.53955539]\n",
      " [ 30.92526338  40.54985356]\n",
      " [ 21.94958306  28.52925723]\n",
      " [ 26.43742322  34.53955539]\n",
      " [ 30.92526338  40.54985356]\n",
      " [ 35.41310354  46.56015173]\n",
      " [ 26.43742322  34.53955539]\n",
      " [ 30.92526338  40.54985356]\n",
      " [ 35.41310354  46.56015173]\n",
      " [ 39.9009437   52.57044989]\n",
      " [ 25.94780547  33.01732179]\n",
      " [ 34.92348579  45.03791812]\n",
      " [ 43.89916612  57.05851446]\n",
      " [ 52.87484644  69.07911079]\n",
      " [ 34.92348579  45.03791812]\n",
      " [ 43.89916612  57.05851446]\n",
      " [ 52.87484644  69.07911079]\n",
      " [ 61.85052676  81.09970712]\n",
      " [ 43.89916612  57.05851446]\n",
      " [ 52.87484644  69.07911079]\n",
      " [ 61.85052676  81.09970712]\n",
      " [ 70.82620708  93.12030345]\n",
      " [ 52.87484644  69.07911079]\n",
      " [ 61.85052676  81.09970712]\n",
      " [ 70.82620708  93.12030345]\n",
      " [ 79.8018874  105.14089978]]\n",
      "kernel output flattened shape: (2, 32)\n",
      "[[ 12.97390274  16.5086609   17.4617429   22.51895906  21.94958306\n",
      "   28.52925723  26.43742322  34.53955539  17.4617429   22.51895906\n",
      "   21.94958306  28.52925723  26.43742322  34.53955539  30.92526338\n",
      "   40.54985356  21.94958306  28.52925723  26.43742322  34.53955539\n",
      "   30.92526338  40.54985356  35.41310354  46.56015173  26.43742322\n",
      "   34.53955539  30.92526338  40.54985356  35.41310354  46.56015173\n",
      "   39.9009437   52.57044989]\n",
      " [ 25.94780547  33.01732179  34.92348579  45.03791812  43.89916612\n",
      "   57.05851446  52.87484644  69.07911079  34.92348579  45.03791812\n",
      "   43.89916612  57.05851446  52.87484644  69.07911079  61.85052676\n",
      "   81.09970712  43.89916612  57.05851446  52.87484644  69.07911079\n",
      "   61.85052676  81.09970712  70.82620708  93.12030345  52.87484644\n",
      "   69.07911079  61.85052676  81.09970712  70.82620708  93.12030345\n",
      "   79.8018874  105.14089978]]\n",
      "L1 shape: (2, 32)\n"
     ]
    }
   ],
   "source": [
    "num_images = 2\n",
    "image_rows = 6\n",
    "image_cols = 6\n",
    "images = np.zeros(shape=(num_images,image_rows,image_cols)) # 2 images\n",
    "\n",
    "for k in range(num_images):\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            images[k,i,j] = (k+1)*(i + j + 1)\n",
    "\n",
    "#print(images)\n",
    "kernel_rows = 3\n",
    "kernel_cols = 3\n",
    "num_kernels = 2\n",
    "hidden_neurons = (image_rows-kernel_rows+1) * (image_cols-kernel_cols+1) * num_kernels\n",
    "output_neurons = 10 # number of image labels\n",
    "\n",
    "print(f\"Hidden neurons: {hidden_neurons}, Output neurons: {output_neurons}\")\n",
    "\n",
    "# initiailize kernels and output layer weights \n",
    "kernels = np.random.random(size=(kernel_rows*kernel_cols, num_kernels))\n",
    "W1 = np.random.random(size=(hidden_neurons, output_neurons))\n",
    "\n",
    "\n",
    "clayer = convolutional_layer(kernels,image_rows,image_cols,kernel_rows,kernel_cols, activation = \"tanh\")\n",
    "\n",
    "L0 = images\n",
    "L1 = clayer.forward(L0, dropout = False)\n",
    "print(f\"L1 shape: {L1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
