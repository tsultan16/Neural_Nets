{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network**:\n",
    "We will now replace the hidden layer from our simple neural network model with a `convolutional layer`. In the usual hidden layer, we multiply the input vector `L0` with a weights matrix `W0`. When the input size is large, i.e. each instance has a large number of feature attributes (e.g. in the case of image data with lots of pixels), we end up with a large number of weights in `W0`. This can lead to the model overfitting the training data and lower the accuracy of the predictions. This problem can be mitigated by introducing a smaller weights matrix, also called a `kernel`, and applying this `kernel` repeatedly over different subsections of the data. So for example, if we have a 28x28 (=784) pixel image input, then instead of multiplying with a weight matrix with 28x28 columns, we can use a 6x6 kernel and multiply it with every 6x6 subsection of the image. We can also use multiple different kernels to process the inputs and pass on a combination of the different kernel outputs onto the next layer.         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class convolutional_layer(object):\n",
    "\n",
    "    '''\n",
    "        class constructor\n",
    "    '''\n",
    "    def __init__(self, K, image_rows, image_cols, kernel_rows, kernel_cols) -> None:\n",
    "        self.K = K\n",
    "        self.image_cols = image_cols\n",
    "        self.image_rows = image_rows\n",
    "        self.kernel_cols = kernel_cols\n",
    "        self.kernel_rows = kernel_rows\n",
    "    \n",
    "    def forward(self, L):\n",
    "        \n",
    "        # reshape the input image array\n",
    "        L = L.reshape(L.shape[0], self.image_rows, self.image_cols)\n",
    "\n",
    "        # get all sub-sections from the image\n",
    "        sections = []\n",
    "        section_count = 0\n",
    "        for i in range(self.image_rows-self.kernel_rows+1):\n",
    "            for j in range(self.image_cols-self.kernel_cols+1):\n",
    "                section = L[:,i:i+self.kernel_rows, j:j+self.kernel_cols]   \n",
    "                section = section.reshape(-1,1,self.kernel_rows,self.kernel_cols)\n",
    "                section_count += 1\n",
    "                #print(f\"Section#{section_count}: , shape: {section.shape}\")\n",
    "                #print(section) \n",
    "                sections.append(section)\n",
    "     \n",
    "        # concatate all sections into a single array\n",
    "        expanded_input = np.concatenate(sections, axis=1)    \n",
    "        #print(f\"expanded input: {expanded_input.shape} \")\n",
    "        #print(expanded_input)\n",
    "        \n",
    "        # flatten the sections\n",
    "        expanded_input = expanded_input.reshape(expanded_input.shape[0]*expanded_input.shape[1], -1) \n",
    "        #print(f\"flattened expanded input: {expanded_input.shape}\")\n",
    "        #print(expanded_input)\n",
    "\n",
    "        # matrix multiplication of flattened image sections with kernels\n",
    "        kernel_output = np.dot(expanded_input, self.K) \n",
    "        return kernel_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 shape: (32, 1)\n"
     ]
    }
   ],
   "source": [
    "num_images = 2\n",
    "image_rows = 6\n",
    "image_cols = 6\n",
    "images = np.zeros(shape=(num_images,image_rows,image_cols)) # 2 images\n",
    "\n",
    "for k in range(2):\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            images[k,i,j] = (k+1)*(i + j + 1)\n",
    "\n",
    "#print(images)\n",
    "kernel_rows = 3\n",
    "kernel_cols = 3\n",
    "num_kernels = 1\n",
    "hidden_neurons = (image_rows-kernel_rows+1) * (image_cols-kernel_cols+1) * num_kernels\n",
    "output_neurons = 10 # number of image labels\n",
    "\n",
    "# initiailize kernels and output layer weights \n",
    "kernels = np.random.random(size=(kernel_rows*kernel_cols, num_kernels))\n",
    "W1 = np.random.random(size=(hidden_neurons, output_neurons))\n",
    "\n",
    "clayer = convolutional_layer(kernels,image_rows,image_cols,kernel_rows,kernel_cols)\n",
    "\n",
    "L0 = images\n",
    "L1 = clayer.forward(L0)\n",
    "print(f\"L1 shape: {L1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
